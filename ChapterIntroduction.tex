\chapter{Introduction}
As mentioned in the previous chapter, I have done this thesis as a part of my work for the company I am employed at - Infomedia\footnote{\url{www.infomedia.dk}}. I have been working for them since my fourth semester at DTU (march 2012), while studying as an IT engineer (B.Eng.). Infomedia is in \underline{short} a company that deals with news monitoring.

Infomedia is the result of a fusion between Berlingske Avisdata and Polinfo in 2002, which means that Infomedia is partly owned by JP/Politikens Hus\footnote{\url{www.jppol.dk}} and Berlingske Media\footnote{\url{www.berlingskemedia.dk}}. It is a company with around 150 employees, of which 107 is contract employees and the rest is student aides in the various departments. Infomedia has various departments, which includes an economy, sales, analysis and an IT department amongst others.\\
I am employed in the IT department (\textit{PIT - Product Innovation and Technology)} as a student programmer (student aide).

Infomedia deals with news monitoring, which means that we have an inflow of articles\footnote{Articles are sent to Infomedia daily, this can be more than 40,000 articles per day.} from various newspapers, news sites, television and radio media (we also have a department in which people are manually listening to radio broadcasts and watching news on television), which we then monitor for content that is of interest to our clients.  This can be a client that wish, to know when their firm, or a product they are using, or manufacturing, is being mentioned in the press. 
Currently (while writing this thesis) the EP\footnote{EP - European Parliament.} election 2014 is going on, and politicians are using the monitoring service from Infomedia to track how they are doing in the media Infomedia\cite{EuropaValg}. Infomedia had a "free for all" news monitoring of the EP election, meaning that all interested could sign up for a getting a daily (weekdays) news monitoring mail from Infomedia, containing the top stories about the EP election. Amongst other things a candidate visibility monitoring was created\cite{InfomediaEpKandidater}. Infomedia have also begun monitoring different social media. Infomedia sells various solutions to clients, so they can get the kind of media monitoring they want.

If a client wishes to get media monitoring from Infomedia, they will contact us and Infomedia will then create search strings, that are strings that contains terms\footnote{A term is, in short, a word or a combination of words.} that a client is interested in (being themselves, a competitor or other things). These search strings will then trigger when an article contains one or more of these terms.
Many local newspapers today are owned by bigger media houses (like the owners of Infomedia) and as such, they will feature a lot of the articles that have also been printed in the "mother paper". This means that the same (or roughly the same\footnote{Articles can be slightly edited in order to make them fit into the layout of the various papers.}) article appear many times in news monitoring. In an effort to make the list of articles presented to the clients, easy to look at, and preventing a client having to read the "same" article over and over, Infomedia has a wish to cluster article duplicates. Infomedia can then present the client with a list of articles, and in that list have further sub lists that contains duplicates of the original aritcle\footnote{Or the longest article rather, as this will tend to contain the most information.}. This also have an economic factor as clients are charged per article read.

Another issue that is caused by article duplicates, is the issue of copyrights. When the same article appears in different media, but without content given from the author of that article, that is breaking the laws concerning copyrights. An example, that is often occurring, is that news telegrams from Reuters\footnote{\url{www.reuters.com}} or Ritzau\footnote{\url{www.ritzau.dk}} is published in a newspaper, but without the source indication. All news media are of course interested in knowing when their material is being published in competing media, therefore are they also interested in having a source indications in the articles. Infomedia actually have a special component in their inflow that looks for Ritzau telegrams.

\section{Thesis Statement}

In this thesis we will try and look into various ways of identifying article duplicates (or articles that have a lot of text in common) within a test corpus\footnote{A days worth of articles from 10/31/2013 - totalling 22.787 articles.} of articles, by using algorithms. The long term goal for Infomedia is having this being implemented in the inflow of articles, and having a look back functionality so that we can group duplicates not just for one day, but for a longer period of time. We want to look into the possibility to get a "better" result set from using a combination of algorithms, rather than just using one, to find article duplicates, and can we perhaps do more than "just" finding duplicates?

\section{Limitation}
Due to the time constraints, this will be done as prototype. I will show through testing how the algorithms works, and analyse their results. These results will then be evaluated and I will comment on these findings. The results will be with a degree of uncertainty as the shear amount of test data is too big to be evaluated by a single person within the time frame for this thesis.