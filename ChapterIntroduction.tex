\chapter{Introduction}
I have been working for Infomedia\footnote{\url{www.infomedia.dk}} since my fourth semester at DTU (march 2012), while studying as an IT engineer (B.Eng.). Infomedia is in \underline{short} a company that deals with news monitoring.

Infomedia is the result of a fusion between Berlingske Avisdata and Polinfo in 2002, which means that Infomedia is partly owned by JP/Politikens Hus\footnote{\url{www.jppol.dk}} and Berlingske Media\footnote{\url{www.berlingskemedia.dk}}. It is a company with around 130 employees, of which a fair amount is student aides like myself. Infomedia has various departments, which includes an economy, sales, analysis and an IT department amongst others.\\
I am employed in the IT department as a student programmer.

Infomedia deals with news monitoring, which means that we have an inflow of articles\footnote{Articles are sent to Infomedia daily, this can be more than 40,000 articles per day.} from various newspapers, news sites, television and radio media, which we then monitor for content that is of interest to our clients. This can be a client that wishes to know when their firm is mentioned in the press or a product they are using, if that is being mentioned. Infomedia have also begun monitoring social media. Infomedia then sells various solutions to clients, for them to get this news monitoring.

One of the things that Infomedia tries to do, is that we want to present our clients with a fast overview of the articles in which terms\footnote{A term is, in short, a word or a combination of words. For the rest of my thesis a term will however only be a single word.}, that trigger our news monitoring, appear. Many local newspapers are today owned by bigger media houses (like the owners of Infomedia) and as such, they will feature a lot of the articles that have also been printed in the "mother paper". This will make the same (or roughly the same\footnote{Articles can be slightly edited in order to make them fit into the layout of the various papers.}) article appear many times in news monitoring. In an effort to make the list of articles presented to the clients, easy to look at, and preventing a client having to read the "same" article many times, Infomedia has a wish to cluster article duplicates. Infomedia can then present the client with a list of articles and in that list have further sub lists that contains duplicates of the original aritcle\footnote{Or the longest article rather, as this will tend to contain the most information.}. This also have an economic factor as clients are charged per article read.

Another issue, is the issue of copyrights and when the same article will appear in different media, but without content given from the author of that article. An example that is often happening is that news telegrams from Reuters\footnote{\url{www.reuters.com}} or Ritzau\footnote{\url{www.ritzau.dk}} is published in a newspaper, but without the source indication. All news media are of course interested in knowing when their material is being published in competing media. This how ever can be tricky business, as official rules on the matter is incredible fuzzy.

I will in this thesis try and look into various ways of identifying article duplicates within a test corpus\footnote{A days worth of articles from 10/31/2013 - totalling 22.787 articles.} of articles, by using algorithms. The long term goal for Infomedia is having this being implemented in the inflow of articles, and having a look back functionality so that we can group duplicates not just for one day, but for a longer period of time. 
